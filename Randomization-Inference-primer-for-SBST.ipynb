{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Randomization Inference Primer for SBST\n",
    "author:\n",
    "- name: Nathaniel Higgins\n",
    "  affiliation: SBST\n",
    "- name: Jake Bowers\n",
    "  affiliation: SBST and University of Illinois\n",
    "date: '`r format(Sys.Date(), \"%B %d, %Y\")`'\n",
    "bibliography: references.bib\n",
    "output:\n",
    "    html_document:\n",
    "      theme: cosmo\n",
    "      toc: yes\n",
    "    pdf_document:\n",
    "      keep_tex: true\n",
    "      number_sections: true\n",
    "      fig_width: 5\n",
    "      fig_height: 5\n",
    "      fig_caption: true\n",
    "      template: bowersarticletemplate.latex\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "cache": "FALSE",
     "classes": [],
     "id": "",
     "include": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Some customization.  You can alter or delete as desired (if you know what you are doing).\n",
    "# knitr settings to control how R chunks work.\n",
    "## To make the html file do\n",
    "## render(\"thefile.Rmd\",output_format=html_document(fig_retina=FALSE))\n",
    "## To make the pdf file do\n",
    "## render(\"thefile.Rmd\",output_format=pdf_document())\n",
    "require(knitr)\n",
    "opts_chunk$set(tidy=TRUE,echo=TRUE,results='markup',strip.white=TRUE,cache=FALSE,highlight=TRUE,width.cutoff=60,size='footnotesize',out.width='.5\\\\textwidth',message=FALSE,comment=NA,fig.env=\"figure\", fig.align=\"center\",fig.lp=\"fig:\",fig.pos=\"H\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Purpose of this document:* To explain what *Randomization Inference\n",
    "(RI)* is, how it can be used by SBST, and how to use RI to calculate\n",
    "test statistics (and maybe point estimates).^[Chapter 2 of @rosenbaum2010design provides an excellent introduction to this.]\n",
    "\n",
    "***1. What Randomization Inference does***\n",
    "\n",
    "Randomization Inference (RI) is used primarily to evaluate hypotheses.\n",
    "So… a question: how is it different from regular old hypothesis testing?\n",
    "Answer: RI doesn’t use distributional assumptions to calculate critical\n",
    "values. The critical values generated by RI are, in this sense, *exact*,\n",
    "rather than being generated by a model meant to approximate the data\n",
    "generating process of a test statistic (what happens in ordinary\n",
    "hypothesis testing).\n",
    "\n",
    "So, for instance, RI could be used to test whether or not the mean\n",
    "$\\overset{\\bar{}}{x}$ of a bunch of numbers is zero. More generally, RI\n",
    "can be used to test hypotheses about the value of a statistic $\\theta$.\n",
    "\n",
    "***2. How does Randomization Inference work?***\n",
    "\n",
    "To begin with, RI is only useful when the data we observe is generated\n",
    "by a process that involves random assignment -- an experiment. RI uses\n",
    "the physical act of randomization -- and the fact that the randomization\n",
    "which we observe *could have gone differently* -- to examine a full set\n",
    "of alternative values for a statistic $\\theta$.\n",
    "\n",
    "***3. An example to illustrate basic mechanics***\n",
    "\n",
    "The value of an outcome variable $y$ could have been observed for both\n",
    "treatment and control units, as in the table below.\n",
    "\n",
    "  Unit Number   $y_{i}$   $T_{i}$\n",
    "  ------------- --------- ---------\n",
    "  1             > 4       0\n",
    "  2             > 5       0\n",
    "  3             > 11      0\n",
    "  4             > 10      0\n",
    "  5             > 3       0\n",
    "  6             > 4       1\n",
    "  7             > 6       1\n",
    "  8             > 2       1\n",
    "  9             > 2       1\n",
    "  10            > 5       1\n",
    "\n",
    "The first 5 observations are of control units ($T_{i} = 0$) and the\n",
    "second 5 observations are of treatment units ($T_{i} = 1$). If we want\n",
    "to test the null hypothesis that the treatment had no effect on $y$, the\n",
    "usual way to do this would be to compare $\\overset{\\bar{}}{y_{1}}$to\n",
    "$\\overset{\\bar{}}{y_{0}}$, (i.e. evaluate\n",
    "$\\theta = \\overset{\\bar{}}{y_{1}} - \\overset{\\bar{}}{y_{0}}$) where\n",
    "$\\overset{\\bar{}}{y_{1}}$ represents the mean of $y$ for treatment units\n",
    "and $\\overset{\\bar{}}{y_{0}}$ represents the mean of $y$ for control\n",
    "units. To implement this example in R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# y values for treatment units\n",
    "y1 <- c(4,5,11,10,3)\n",
    "n1 <- length(y1)\n",
    "\n",
    "# y values for control units\n",
    "y0 <- c(4,6,2,2,5)\n",
    "n0 <- length(y0)\n",
    "\n",
    "# means\n",
    "y1.bar <- sum(y1)/n1\n",
    "y0.bar <- sum(y0)/n0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, $\\overset{\\bar{}}{y_{1}} = 6.6$ and\n",
    "$\\overset{\\bar{}}{y_{0}} = 3.8$. To test $H_{0}:\\mu_{1} - \\mu_{0} = 0$\n",
    "(no effect of treatment) using classical statistics, we compare the two\n",
    "means, $\\overset{\\bar{}}{y_{1}} - \\overset{\\bar{}}{y_{0}} = 2.8$,\n",
    "calculate the standard error of the difference in means (SEDM), and\n",
    "create a t-statistic. To calculate the SEDM, first calculate the\n",
    "standard error of $\\overset{\\bar{}}{y_{1}}$ and\n",
    "$\\overset{\\bar{}}{y_{0}}$\n",
    "\n",
    "$se_{x} = sd_{x}/.$\n",
    "\n",
    "Or in R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "var1 <- sum((y1 - y1.bar)^2)/(n1-1)\n",
    "sd1 <- sqrt(var1)\n",
    "se1 <- sd1/sqrt(n1)\n",
    "var0 <- sum((y0 - y0.bar)^2)/(n0-1)\n",
    "sd0 <- sqrt(var0)\n",
    "se0 <- sd0/sqrt(n0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the null hypothesis, we then calculate SEDM as\n",
    "\n",
    "$SEDM =$\n",
    "\n",
    "Or in R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "sedm <- sqrt(se1^2 + se0^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which yields 1.81659. Take the difference in means of 2.8 and divide by\n",
    "the SEDM to get the t-statistic of 1.541349. Or, of course, just take a\n",
    "shortcut and get right to the t-stat with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "ttest1 <- t.test(y1,y0)\n",
    "ttest1\n",
    "ttest1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However we get here, we do not reject the null hypothesis (at\n",
    "$\\alpha = 0.05$) because the t-stat is less than 2.\n",
    "\n",
    "Now, how would something similar look using an RI framework? In the RI\n",
    "framework, we utilize the fact that although the randomization worked\n",
    "out such that observations 1 through 5 were assigned to treatment and\n",
    "observations 6 through 10 were assigned to control, this was not the\n",
    "only way assignment could have gone. It could have, in fact, gone a\n",
    "whole bunch of other ways. Instead of the treatment group being made up\n",
    "of observations 1 through 5,\n",
    "\n",
    "$\\{ 1,2,3,4,5\\}$,\n",
    "\n",
    "it could have been made up of observations 1 through 4, plus observation\n",
    "6 (or 7 or 8 or 9 or 10),\n",
    "\n",
    "$\\{ 1,2,3,4,6\\}$\n",
    "\n",
    "...\n",
    "\n",
    "$\\{ 1,2,3,4,10\\}.$\n",
    "\n",
    "In fact, when separating a dset with 10 observations into two sets of 5,\n",
    "you are simply creating one group of 5 (the treatment group, say) by\n",
    "sampling without replacement, with the other group of 5 (the control\n",
    "group) being the compliment (whatever is not sampled to be a part of the\n",
    "first group). That is, you are choosing 5 from a group of 10 without\n",
    "replacement. There are a total of n-choose-k (choose(10,5) = 252)\n",
    "different randomizations that could have occurred. This is the key to\n",
    "randomization inference.\n",
    "\n",
    "***3. Randomization Inference***\n",
    "\n",
    "To test the null hypothesis of no effect in the RI framework, we don’t\n",
    "test $H_{0}:\\mu_{1} - \\mu_{0} = 0$ -- we test the null hypothesis of *no\n",
    "effect*, i.e. no effect at all on any unit. Testing this null is\n",
    "different from testing for no effect *on average*. This means that we\n",
    "test whether or not the data are consistent with a treatment effect of 0\n",
    "on each unit.\n",
    "\n",
    "If the effect of treatment on each unit were precisely 0, then the\n",
    "assignment to treatment was immaterial to generating the $y$ data that\n",
    "we actually observed. No matter what we did -- no matter which of the\n",
    "252 possible randomizations we ended up with -- we would have observed\n",
    "the same $y$ data that we did actually observe (unit 1 would have\n",
    "produced $y_{1} = 4$, and so on). Our goal now will be to find the value\n",
    "of the test statistic $\\theta$ under each of the 252 possible\n",
    "assignments to treatment, so that we can see where our test statistic\n",
    "falls in the distribution. Is it unusual/extreme? Or is it a value in\n",
    "the heart of the distribution? Let’s find out.\n",
    "\n",
    "Recall the data as we observed it:\n",
    "\n",
    "  Unit Number   $y_{i}$   $T_{i}$\n",
    "  ------------- --------- ---------\n",
    "  1             > 4       0\n",
    "  2             > 5       0\n",
    "  3             > 11      0\n",
    "  4             > 10      0\n",
    "  5             > 3       0\n",
    "  6             > 4       1\n",
    "  7             > 6       1\n",
    "  8             > 2       1\n",
    "  9             > 2       1\n",
    "  10            > 5       1\n",
    "\n",
    "If instead the assignment to treatment were exactly reversed, as in\n",
    "\n",
    "  Unit Number   $y_{i}$   $T_{i}$\n",
    "  ------------- --------- ---------\n",
    "  1             > 4       1\n",
    "  2             > 5       1\n",
    "  3             > 11      1\n",
    "  4             > 10      1\n",
    "  5             > 3       1\n",
    "  6             > 4       0\n",
    "  7             > 6       0\n",
    "  8             > 2       0\n",
    "  9             > 2       0\n",
    "  10            > 5       0\n",
    "\n",
    "then the statistic of interest $\\theta$ (difference in means) would have\n",
    "taken on a value of -2.8 instead of 2.8. If instead the assignment to\n",
    "treatment were\n",
    "\n",
    "  Unit Number   $y_{i}$   $T_{i}$\n",
    "  ------------- --------- ---------\n",
    "  1             > 4       1\n",
    "  2             > 5       0\n",
    "  3             > 11      1\n",
    "  4             > 10      0\n",
    "  5             > 3       1\n",
    "  6             > 4       0\n",
    "  7             > 6       1\n",
    "  8             > 2       0\n",
    "  9             > 2       1\n",
    "  10            > 5       0\n",
    "\n",
    "then $\\theta$ is equal to 0. What we need is a systematic way to find\n",
    "each of the possible assignments to treatment, calculate $\\theta$ each\n",
    "time, and save the values of $\\theta$ so that we can explore its\n",
    "distribution. We want to look at each possible assignment of units 1\n",
    "through 10 to treatment, with the compliment of that set being assigned\n",
    "to control. To do this, we can use the combinations function in the\n",
    "gtools package. Invoking combinations(10,5) provides us with a matrix of\n",
    "all 252 combinations, with each row representing the units assigned to\n",
    "treatment. For example, the first 10 rows of this matrix would look\n",
    "like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Create the set of all possible assignments to treatment\n",
    "library(gtools)\n",
    "treat <- combinations(10,5)\n",
    "treat[1:10,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to easily recalculate $\\theta$ for each of the 252\n",
    "observations, storing them as we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Create a vector y containing all outcomes\n",
    "y <- c(y1,y0)\n",
    "# Initialize a vector to store all the thetas\n",
    "theta <- rep(0,choose(10,5))\n",
    "# Calculate y1.bar for the first assignment\n",
    "mean(y[treat[1,]])\n",
    "# Calculate y0.bar for the first assignment\n",
    "mean(y[-treat[1,]])\n",
    "# Calculate theta for the first assignment\n",
    "mean(y[treat[1,]]) - mean(y[-treat[1,]])\n",
    "# Now automate that pattern for each of the 252 assignments\n",
    "for (i in 1:(choose(10,5))){\n",
    "\ttheta[i] <- mean(y[treat[i,]]) - mean(y[-treat[i,]])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! Now we can look at the vector theta and examine how 2.8 (the\n",
    "original statistic that we calculated based on the randomization as it\n",
    "actually happened) compares, i.e. where it falls in the distribution.\n",
    "It’s probably easiest to first look at data like this in an ordered\n",
    "fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Sort from lowest to highest\n",
    "theta <- theta[order(theta)]\n",
    "# Calculate exact quantile (1/252) for each possible theta\n",
    "# How many of 252 are less than or equal to theta\\_i?\n",
    "idx <- 1:(length(theta))\n",
    "quant <- idx/(length(idx))\n",
    "# Now find 2.8 on this mapping\n",
    "which(theta == 2.8)\n",
    "# Note that there are more than 1 (because of ties)\n",
    "# Look up the quantiles of theta = 2.8\n",
    "quant[which(theta == 2.8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So depending on how we deal with ties, anywhere between about 89% and\n",
    "92% of randomization assignments would have resulted in a theta less\n",
    "than or equal to 2.8 (the theta we observed), given that the treatment\n",
    "had no effect. So should we be surprised by a theta of 2.8? Does a theta\n",
    "of 2.8 provide evidence against the null? Some. If the null is true, 2.8\n",
    "is unusually large, in the sense that theta is *usually* less than 2.8.\n",
    "\n",
    "Note that all of this is akin to calculating a p-value for a one-sided\n",
    "test. To do a two-sided test, we’d look at the absolute values of theta\n",
    "rather than their actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Calculate absolute values of theta\n",
    "abs.theta <- abs(theta)\n",
    "# Re-sort from lowest to highest\n",
    "abs.theta <- abs.theta[order(abs.theta)]\n",
    "# Look at two-sided p-value(s)\n",
    "quant[which(abs.theta == 2.8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, because of ties, there are actually twenty different random\n",
    "assignments that all lead to a theta of |2.8|. This makes a theta of 2.8\n",
    "seem a little less unlikely, but it’s still unlikely (at least 77% of\n",
    "thetas are less than 2.8 when there is no treatment effect).\n",
    "\n",
    "# What about larger experiments?\n",
    "\n",
    "Randomization inference reflects the design of the experiment. Because of this, it turns out to have good properties even when sample sizes are large. For example, @imbens2005robust show how 2SLS has terrible properties when an instrumental variable is a weak instrument and the sample size is about 500,000.\n",
    "\n",
    "In that case, however, you could not calculate $p$-values from the exact or enumerated randomization distribution. Rather, you would want to sample from that distribution. Here, for example, we use only 100 samples from the exact distribution that we used above. We also show a tool that is slightly easier.\n",
    "\n",
    "First, install the development version of RItools (\"Randomization inference tools\") [@bowers2009ritools]. (The following installs the development version of RItools and devtools into a local R library rather than your global R library.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "if(!dir.exists(\"libraries\")){\n",
    "\tdir.create(\"libraries\")\n",
    "}\n",
    ".libPaths(\"libraries\") ## make the default place for libraries the local one\n",
    "\n",
    "## Install devtools in the local library if it is not already installed\n",
    "installedpackages<-installed.packages(lib.loc=\"libraries\")\n",
    "if(!any(installedpackages[,\"Package\"]==\"devtools\")) {\n",
    "  install.packages(\"devtools\", repos=\"http://cran.rstudio.com\")\n",
    "  library(devtools)\n",
    "}\n",
    "\n",
    "## Install RItools development version if it is not already installed\n",
    "if(!any(installedpackages[,\"Package\"]==\"RItools\")) {\n",
    "  install_github(\"markmfredrickson/RItools@randomization-distribution\")\n",
    "}\n",
    "library(RItools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, remember that randomization inference requires a description of the experimental design, a hypothesis, and a test statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "## the design is simple: complete random assignment of 5 out of 10 to treatment\n",
    "\n",
    "## Create a treatment assignment column\n",
    "Z<-c(rep(1,5),rep(0,5))\n",
    "\n",
    "## For now, with the development package, create a blocking indicator that is all 1.\n",
    "b<-rep(1,10)\n",
    "\n",
    "randomassignment<-simpleRandomSampler(z=Z,b=b)\n",
    "\n",
    "## Notice that randomassignment is a function that produces draws from the set of possible treatments:\n",
    "\n",
    "randomassignment(5)$samples\n",
    "\n",
    "## Let's use the mean difference test statistic for simplicity\n",
    "## a bunch of these are hard coded in the package, but I'll write one out here.\n",
    "meandiffTZ <- function(ys, z) {\n",
    "    mean(ys[z==1]) - mean(ys[z==0])\n",
    "}\n",
    "\n",
    "meandifftestExact<-RItest(y=y,\n",
    "                     z=Z,\n",
    "                     test.stat=meandiffTZ,\n",
    "                     sampler = randomassignment)\n",
    "## This provides a one-sided p-value by default\n",
    "meandifftestExact\n",
    "\n",
    "## Here is the two-sided p-value\n",
    "2 * min( meandifftestExact, 1 - meandifftestExact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's only use 100 draws from the possible 252. And, to show that this method comes with a bit of simulation error, I do it multiple times and calculate the standard deviation of the p-values. Notice that if you drew 10,000 times, your simulation error would be very small (and you could approximately calculate it using $\\sqrt{p(1-p)/B}$ where $B$ is the number of simulations). Notice below sampling in this way provides an unbiased estimate of the exact $p$-value? Also, notice that simulation error can be large --- a difference of 2*.03 in $p$-value can push you over the magic .05 line easily. So, in this case, we would much prefer to use use the exact distribution. That said, if we had drawn 10,000 simulations from a larger study (say, with $N=100$), then we could have had simulation error below .003."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "cache": "TRUE",
     "classes": [],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "set.seed(1234567)\n",
    "meandifftestSim<-RItest(y=y,\n",
    "                     z=Z,\n",
    "                     test.stat=meandiffTZ,\n",
    "                     sampler = randomassignment,\n",
    "\t\t     samples = 100)\n",
    "meandifftestSim\n",
    "\n",
    "simedps<-replicate(1000,RItest(y=y,\n",
    "                     z=Z,\n",
    "                     test.stat=meandiffTZ,\n",
    "                     sampler = randomassignment,\n",
    "\t\t     samples = 100))\n",
    "\n",
    "summary(simedps)\n",
    "sd(simedps)\n",
    "\n",
    "## Approximate and quick formula for error based on simulation.\n",
    "## sqrt( ( p * (1-p)) / number of sims )\n",
    "sqrt( .11*(1-.11) /  100 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
